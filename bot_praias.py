import re
import json
import logging
from datetime import datetime
from pathlib import Path

import requests
from bs4 import BeautifulSoup
from telegram import Update
from telegram.ext import Application, MessageHandler, filters, ContextTypes
from apscheduler.schedulers.background import BackgroundScheduler

try:
    import pdfplumber
    PDF_SUPPORT = True
except ImportError:
    PDF_SUPPORT = False

TELEGRAM_TOKEN = "8537829811:AAEMKGX_w3kRLPwEQFQ-QnUWO3BG9YmJECk"
DADOS_FILE = Path.home() / "dados_praias.json"

logging.basicConfig(level=logging.INFO)
log = logging.getLogger("bot_praias")

# Todas as 27 praias monitoradas pela CPRH com seus municÃ­pios
PRAIAS_CONHECIDAS = [
    # Litoral Norte
    {"praia": "Carne de Vaca", "municipio": "Goiana"},
    {"praia": "Pontas de Pedra (Pedrinhas)", "municipio": "Goiana"},
    {"praia": "Pontas de Pedra (Praia do Meio)", "municipio": "Goiana"},
    {"praia": "Catuama", "municipio": "Goiana"},
    {"praia": "Jaguaribe", "municipio": "ItamaracÃ¡"},
    {"praia": "Pilar", "municipio": "ItamaracÃ¡"},
    {"praia": "Forte Orange", "municipio": "ItamaracÃ¡"},
    {"praia": "Maria Farinha", "municipio": "Paulista"},
    {"praia": "Janga (Cond. Roberto Barbosa)", "municipio": "Paulista"},
    {"praia": "Janga (Rua BetÃ¢nia)", "municipio": "Paulista"},
    # RegiÃ£o Metropolitana - Olinda/Recife
    {"praia": "Rio Doce", "municipio": "Olinda"},
    {"praia": "Bairro Novo", "municipio": "Olinda"},
    {"praia": "Carmo", "municipio": "Olinda"},
    {"praia": "Milagres", "municipio": "Olinda"},
    {"praia": "Pina", "municipio": "Recife"},
    {"praia": "Boa Viagem (Posto 8)", "municipio": "Recife"},
    {"praia": "Boa Viagem (Posto 15)", "municipio": "Recife"},
    # Litoral Sul - JaboatÃ£o
    {"praia": "Piedade", "municipio": "JaboatÃ£o dos Guararapes"},
    {"praia": "Candeias (Conj. Candeias II)", "municipio": "JaboatÃ£o dos Guararapes"},
    {"praia": "Candeias (Rest. CandelÃ¡ria)", "municipio": "JaboatÃ£o dos Guararapes"},
    {"praia": "Barra de Jangadas", "municipio": "JaboatÃ£o dos Guararapes"},
    # Igarassu
    {"praia": "Praia do CapitÃ£o (Mangue Seco)", "municipio": "Igarassu"},
    # Litoral Sul - Cabo / Ipojuca
    {"praia": "Enseada dos Corais", "municipio": "Cabo de Santo Agostinho"},
    {"praia": "Gaibu", "municipio": "Cabo de Santo Agostinho"},
    {"praia": "Suape", "municipio": "Cabo de Santo Agostinho"},
    {"praia": "Porto de Galinhas", "municipio": "Ipojuca"},
    {"praia": "Ponta de Serrambi", "municipio": "Ipojuca"},
    # Litoral Sul - TamandarÃ©
    {"praia": "Praia dos Carneiros", "municipio": "TamandarÃ©"},
    {"praia": "TamandarÃ© (Hotel Marinas)", "municipio": "TamandarÃ©"},
    {"praia": "TamandarÃ© (Rua Nilo Gouveia)", "municipio": "TamandarÃ©"},
    {"praia": "SÃ£o JosÃ© da Coroa Grande", "municipio": "SÃ£o JosÃ© da Coroa Grande"},
]


# â”€â”€â”€ Scraper CPRH â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

def parse_status(texto):
    t = texto.upper().strip()
    if "IMPR" in t:
        return "IMPRÃ“PRIA"
    if "PR" in t:
        return "PRÃ“PRIA"
    return None


def scrape_pdf(pdf_url):
    """Extrai dados de um PDF da CPRH."""
    praias = []
    try:
        log.info(f"Baixando PDF: {pdf_url}")
        resp = requests.get(pdf_url, timeout=30, verify=False)
        pdf_path = Path.home() / "temp_balneabilidade.pdf"
        pdf_path.write_bytes(resp.content)

        status_atual = None
        municipio_atual = ""

        with pdfplumber.open(pdf_path) as pdf:
            for page in pdf.pages:
                texto = page.extract_text() or ""
                for linha in texto.splitlines():
                    linha = linha.strip()
                    if not linha:
                        continue

                    # Detecta linha de status
                    if re.match(r"^(PR[OÃ“]PRIA|IMPR[OÃ“]PRIA)$", linha, re.IGNORECASE):
                        status_atual = parse_status(linha)
                        continue

                    # Detecta municÃ­pio (linha curta sem nÃºmeros)
                    if (len(linha) < 35
                            and not any(c.isdigit() for c in linha)
                            and "praia" not in linha.lower()
                            and "em frente" not in linha.lower()
                            and linha not in ["PRÃ“PRIA", "IMPRÃ“PRIA"]):
                        municipio_atual = linha
                        continue

                    # Linha de praia
                    if ("praia" in linha.lower() or "em frente" in linha.lower()) and status_atual:
                        # Extrai nome limpo da praia
                        nome = re.sub(r"(?i)^praia\s+(de|da|do|dos|das)\s+", "", linha)
                        nome = nome.split(",")[0].split("â€“")[0].strip()
                        praias.append({
                            "praia": nome,
                            "status": status_atual,
                            "municipio": municipio_atual
                        })

        pdf_path.unlink(missing_ok=True)
        log.info(f"PDF extraÃ­do: {len(praias)} praias")

    except Exception as e:
        log.error(f"Erro ao processar PDF: {e}")

    return praias


def encontrar_pdf_cprh():
    """Busca o link do PDF mais recente no site da CPRH."""
    try:
        headers = {"User-Agent": "Mozilla/5.0"}
        resp = requests.get(
            "https://www2.cprh.pe.gov.br/monitoramento-ambiental/balneabilidade/",
            headers=headers, timeout=15, verify=False
        )
        soup = BeautifulSoup(resp.text, "html.parser")

        for a in soup.find_all("a", href=True):
            href = a["href"]
            if "balneabilidade" in href.lower() and href.lower().endswith(".pdf"):
                if href.startswith("http"):
                    return href
                return "https://www2.cprh.pe.gov.br/" + href.lstrip("/")

        # Tenta tambÃ©m na pÃ¡gina de uploads do WordPress
        for a in soup.find_all("a", href=True):
            href = a["href"]
            if "uploads" in href and href.lower().endswith(".pdf"):
                return href if href.startswith("http") else "https://www2.cprh.pe.gov.br/" + href.lstrip("/")

    except Exception as e:
        log.error(f"Erro ao buscar PDF: {e}")

    return None


def atualizar_dados():
    """Busca dados da CPRH e atualiza o arquivo local."""
    log.info("ğŸ”„ Atualizando dados da CPRH...")

    if not PDF_SUPPORT:
        log.error("pdfplumber nÃ£o instalado")
        return

    pdf_url = encontrar_pdf_cprh()
    praias = []

    if pdf_url:
        praias = scrape_pdf(pdf_url)
    else:
        log.warning("PDF nÃ£o encontrado no site da CPRH")

    if praias:
        dados = {
            "atualizado_em": datetime.now().isoformat(),
            "total_proprias": sum(1 for p in praias if p["status"] == "PRÃ“PRIA"),
            "total_improprias": sum(1 for p in praias if p["status"] == "IMPRÃ“PRIA"),
            "praias": praias,
            "fonte": "cprh"
        }
        DADOS_FILE.write_text(json.dumps(dados, ensure_ascii=False, indent=2), encoding="utf-8")
        log.info(f"âœ… {len(praias)} praias salvas da CPRH")
    else:
        log.warning("âš ï¸ Scraper nÃ£o encontrou dados â€” mantendo dados anteriores")


# â”€â”€â”€ Dados de exemplo (fallback com todas as 27 praias) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

def dados_exemplo():
    """Retorna dados de exemplo com todas as praias conhecidas."""
    # Baseado no boletim mais recente (semana 8/2026)
    status_map = {
        "Jaguaribe": "IMPRÃ“PRIA",
        "Pilar": "PRÃ“PRIA",
        "Forte Orange": "PRÃ“PRIA",
        "Maria Farinha": "PRÃ“PRIA",
        "Janga (Cond. Roberto Barbosa)": "PRÃ“PRIA",
        "Janga (Rua BetÃ¢nia)": "PRÃ“PRIA",
        "Rio Doce": "IMPRÃ“PRIA",
        "Bairro Novo": "IMPRÃ“PRIA",
        "Carmo": "IMPRÃ“PRIA",
        "Milagres": "IMPRÃ“PRIA",
        "Pina": "IMPRÃ“PRIA",
        "Boa Viagem (Posto 8)": "PRÃ“PRIA",
        "Boa Viagem (Posto 15)": "PRÃ“PRIA",
        "Piedade": "PRÃ“PRIA",
        "Candeias (Conj. Candeias II)": "IMPRÃ“PRIA",
        "Candeias (Rest. CandelÃ¡ria)": "IMPRÃ“PRIA",
        "Barra de Jangadas": "PRÃ“PRIA",
        "Enseada dos Corais": "PRÃ“PRIA",
        "Gaibu": "IMPRÃ“PRIA",
        "Suape": "IMPRÃ“PRIA",
        "Porto de Galinhas": "PRÃ“PRIA",
        "Ponta de Serrambi": "PRÃ“PRIA",
        "Praia dos Carneiros": "PRÃ“PRIA",
        "TamandarÃ© (Hotel Marinas)": "PRÃ“PRIA",
        "TamandarÃ© (Rua Nilo Gouveia)": "PRÃ“PRIA",
        "Praia do CapitÃ£o (Mangue Seco)": "IMPRÃ“PRIA",
        "SÃ£o JosÃ© da Coroa Grande": "PRÃ“PRIA",
    }

    praias = []
    for p in PRAIAS_CONHECIDAS:
        praias.append({
            "praia": p["praia"],
            "municipio": p["municipio"],
            "status": status_map.get(p["praia"], "PRÃ“PRIA")
        })

    return {
        "atualizado_em": "2026-02-19T00:00:00",
        "total_proprias": sum(1 for p in praias if p["status"] == "PRÃ“PRIA"),
        "total_improprias": sum(1 for p in praias if p["status"] == "IMPRÃ“PRIA"),
        "praias": praias,
        "fonte": "exemplo"
    }


def carregar_dados():
    if DADOS_FILE.exists():
        dados = json.loads(DADOS_FILE.read_text(encoding="utf-8"))
        # Se tem dados reais da CPRH, usa. Se tem menos de 10 praias, usa exemplo
        if len(dados.get("praias", [])) >= 10:
            return dados
    d = dados_exemplo()
    DADOS_FILE.write_text(json.dumps(d, ensure_ascii=False, indent=2), encoding="utf-8")
    return d


# â”€â”€â”€ FormataÃ§Ã£o â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

def formatar_boletim():
    dados = carregar_dados()
    data = datetime.fromisoformat(dados["atualizado_em"]).strftime("%d/%m/%Y")
    eh_exemplo = dados.get("fonte") == "exemplo"

    linhas = [
        "ğŸ–ï¸ BALNEABILIDADE â€” PERNAMBUCO",
        f"ğŸ“… Boletim de: {data}" + (" _(referÃªncia)_" if eh_exemplo else ""),
        f"âœ… PrÃ³prias: {dados['total_proprias']}  |  âŒ ImprÃ³prias: {dados['total_improprias']}",
        ""
    ]

    municipios = {}
    for p in dados["praias"]:
        mun = p.get("municipio") or "Outras"
        municipios.setdefault(mun, []).append(p)

    for mun, lista in municipios.items():
        linhas.append(f"ğŸ“ {mun.upper()}")
        for p in lista:
            icone = "ğŸŸ¢" if p["status"] == "PRÃ“PRIA" else "ğŸ”´"
            linhas.append(f"  {icone} {p['praia']}")
        linhas.append("")

    linhas.append("ğŸ“Š Fonte: CPRH â€” cprh.pe.gov.br")
    linhas.append("âš ï¸ Evite o mar 24h apÃ³s chuvas fortes")

    return "\n".join(linhas)


# â”€â”€â”€ Bot Telegram â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

async def responder(update: Update, context: ContextTypes.DEFAULT_TYPE):
    await update.message.reply_text(formatar_boletim())


def main():
    import urllib3
    urllib3.disable_warnings()

    # Tenta buscar dados reais da CPRH
    atualizar_dados()

    # Garante que temos dados (reais ou exemplo)
    carregar_dados()

    # Agenda atualizaÃ§Ã£o toda sexta Ã s 14h
    scheduler = BackgroundScheduler()
    scheduler.add_job(atualizar_dados, "cron", day_of_week="fri", hour=14, minute=0)
    scheduler.start()
    log.info("â° Agendamento: toda sexta Ã s 14h")

    app = Application.builder().token(TELEGRAM_TOKEN).build()
    app.add_handler(MessageHandler(filters.ALL, responder))
    log.info("ğŸ¤– Bot iniciado!")
    app.run_polling(drop_pending_updates=True)


if __name__ == "__main__":
    main()
